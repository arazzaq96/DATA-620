{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33dd5113",
   "metadata": {},
   "source": [
    "# Project 3: Name Gender Classification using NLTK\n",
    "**Course**: DATA 620  \n",
    "**Student**: Ariba Mandavia\n",
    "\n",
    "\n",
    "## Objective\n",
    "Build a gender classifier using first names from the NLTK Names Corpus.  \n",
    "Explore different classifiers (Naive Bayes, Decision Tree, MaxEnt), use custom features, and compare performance on dev-test and test datasets. \n",
    "\n",
    "## Introduction\n",
    "\n",
    "This project explores how well we can classify the gender (male or female) of a person based on their first name using Natural Language Processing techniques.\n",
    "\n",
    "We use the `names` corpus from the NLTK library, which includes over 7,000 first names labeled with gender. We apply multiple classification algorithms — Naive Bayes, Decision Tree, and Maximum Entropy — and evaluate their performance.\n",
    "\n",
    "By engineering meaningful features from names (like suffixes, vowels, and first/last letters), we aim to understand:\n",
    "- Which features are most predictive of gender?\n",
    "- Which classifier performs best on unseen data?\n",
    "- How reliable and generalizable are the results?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a342ea42",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier\n",
    "\n",
    "We start with the Naive Bayes classifier, a simple probabilistic model that works well for text classification problems. It assumes independence between features and calculates the probability of each label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536c1647",
   "metadata": {},
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import names\n",
    "from nltk import NaiveBayesClassifier, classify\n",
    "from nltk.classify import DecisionTreeClassifier, MaxentClassifier\n",
    "\n",
    "# Download corpus if needed\n",
    "nltk.download('names')\n",
    "\n",
    "# Load and shuffle names\n",
    "labeled_names = [(name, 'male') for name in names.words('male.txt')] + \\\n",
    "                [(name, 'female') for name in names.words('female.txt')]\n",
    "random.shuffle(labeled_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3066a951",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We use the `names` corpus from NLTK. It contains:\n",
    "- 2,948 male names\n",
    "- 5,094 female names\n",
    "\n",
    "The data is randomly shuffled and split as follows:\n",
    "- **Training set**: ~6,400 names\n",
    "- **Dev-test set**: 500 names (used for tuning and evaluation)\n",
    "- **Test set**: 500 names (used only for final model evaluation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c41cc70",
   "metadata": {},
   "source": [
    "## Step 1: Load and Prepare the Data\n",
    "# Split data\n",
    "test_names = labeled_names[:500]\n",
    "devtest_names = labeled_names[500:1000]\n",
    "train_names = labeled_names[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68963ecc",
   "metadata": {},
   "source": [
    "## Feature Design\n",
    "\n",
    "We designed features to capture common gendered patterns in names:\n",
    "\n",
    "- **Last letter**: many female names end in \"a\", \"e\"\n",
    "- **First letter**: may reflect gendered initials\n",
    "- **Name length**: some gender trends in length\n",
    "- **Vowel count**: more vowels may be common in female names\n",
    "- **Suffixes (last 2–3 letters)**: key indicators like \"ia\", \"us\", \"na\", etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41248c1",
   "metadata": {},
   "source": [
    "## Step 2: Feature Engineering\n",
    "\n",
    "# Feature extractor\n",
    "def gender_features(name):\n",
    "    return {\n",
    "        'last_letter': name[-1].lower(),\n",
    "        'first_letter': name[0].lower(),\n",
    "        'length': len(name),\n",
    "        'vowel_count': sum(1 for c in name.lower() if c in 'aeiou'),\n",
    "        'suffix2': name[-2:].lower(),\n",
    "        'suffix3': name[-3:].lower()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa26be2",
   "metadata": {},
   "source": [
    "We apply the feature extractor to all three data subsets.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c8351f",
   "metadata": {},
   "source": [
    "## Step 3: Create Feature Sets\n",
    "\n",
    "\n",
    "# Feature sets\n",
    "train_set = [(gender_features(n), g) for (n, g) in train_names]\n",
    "devtest_set = [(gender_features(n), g) for (n, g) in devtest_names]\n",
    "test_set = [(gender_features(n), g) for (n, g) in test_names]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b316a7e",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier\n",
    "\n",
    "We start with the Naive Bayes classifier, a simple probabilistic model that works well for text classification problems. It assumes independence between features and calculates the probability of each label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1539975",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier\n",
    "\n",
    "nb_classifier = NaiveBayesClassifier.train(train_set)\n",
    "print(\"\\nNaive Bayes Classifier:\")\n",
    "print(\"  Dev-Test Accuracy:\", classify.accuracy(nb_classifier, devtest_set))\n",
    "print(\"  Test Accuracy:\", classify.accuracy(nb_classifier, test_set))\n",
    "nb_classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb07d0da",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier\n",
    "\n",
    "The Decision Tree classifier learns rules from the training data and builds a tree of decisions to classify new names. It may overfit on small or noisy data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc38ea39",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier\n",
    "\n",
    "The Decision Tree classifier learns rules from the training data and builds a tree of decisions to classify new names. It may overfit on small or noisy data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4dff51",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier.train(train_set)\n",
    "print(\"\\nDecision Tree Classifier:\")\n",
    "print(\"  Dev-Test Accuracy:\", classify.accuracy(dt_classifier, devtest_set))\n",
    "print(\"  Test Accuracy:\", classify.accuracy(dt_classifier, test_set))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55a2a9b",
   "metadata": {},
   "source": [
    "## MaxEnt Classifier\n",
    "\n",
    "Maximum Entropy (MaxEnt) is a logistic regression-based model that finds the best weights for features without assuming independence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0a6677",
   "metadata": {},
   "source": [
    "## MaxEnt Classifier\n",
    "\n",
    "Maximum Entropy (MaxEnt) is a logistic regression-based model that finds the best weights for features without assuming independence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6ebf04",
   "metadata": {},
   "source": [
    "# MaxEnt Classifier\n",
    "\n",
    "maxent_classifier = MaxentClassifier.train(train_set, max_iter=10)\n",
    "print(\"\\nMaxEnt Classifier:\")\n",
    "print(\"  Dev-Test Accuracy:\", classify.accuracy(maxent_classifier, devtest_set))\n",
    "print(\"  Test Accuracy:\", classify.accuracy(maxent_classifier, test_set))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e489a94",
   "metadata": {},
   "source": [
    "## Ensemble Classifier\n",
    "\n",
    "We create an ensemble classifier that combines the predictions from all three models using majority voting. This ensemble approach helps smooth out individual classifier weaknesses and increases robustness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be33a43e",
   "metadata": {},
   "source": [
    "## Ensemble Classifier\n",
    "\n",
    "We create an ensemble classifier that combines the predictions from all three models using majority voting. This ensemble approach helps smooth out individual classifier weaknesses and increases robustness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e4a350",
   "metadata": {},
   "source": [
    "# Ensemble Classifier (Voting)\n",
    "def ensemble_classify(name):\n",
    "    features = gender_features(name)\n",
    "    votes = [\n",
    "        nb_classifier.classify(features),\n",
    "        dt_classifier.classify(features),\n",
    "        maxent_classifier.classify(features)\n",
    "    ]\n",
    "    return max(set(votes), key=votes.count)\n",
    "\n",
    "ensemble_dev_acc = sum(ensemble_classify(n) == g for (n, g) in devtest_names) / len(devtest_names)\n",
    "ensemble_test_acc = sum(ensemble_classify(n) == g for (n, g) in test_names) / len(test_names)\n",
    "\n",
    "print(\"\\nEnsemble Classifier:\")\n",
    "print(\"  Dev-Test Accuracy:\", ensemble_dev_acc)\n",
    "print(\"  Test Accuracy:\", ensemble_test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fe5db1",
   "metadata": {},
   "source": [
    "\n",
    "# Cross-Validation Function\n",
    "def cross_validate(data, k=5):\n",
    "    random.shuffle(data)\n",
    "    chunk_size = len(data) // k\n",
    "    accuracies = []\n",
    "\n",
    "    for i in range(k):\n",
    "        test = data[i*chunk_size:(i+1)*chunk_size]\n",
    "        train = data[:i*chunk_size] + data[(i+1)*chunk_size:]\n",
    "        train_set = [(gender_features(n), g) for (n, g) in train]\n",
    "        test_set = [(gender_features(n), g) for (n, g) in test]\n",
    "\n",
    "        model = NaiveBayesClassifier.train(train_set)\n",
    "        acc = classify.accuracy(model, test_set)\n",
    "        accuracies.append(acc)\n",
    "\n",
    "    return sum(accuracies) / k\n",
    "\n",
    "cv_acc = cross_validate(labeled_names, k=5)\n",
    "print(f\"\\n5-Fold Cross-Validated Naive Bayes Accuracy: {cv_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303d8689",
   "metadata": {},
   "source": [
    "## Results and Interpretation\n",
    "\n",
    "| Classifier           | Dev-Test Accuracy | Test Accuracy |\n",
    "|----------------------|-------------------|---------------|\n",
    "| Naive Bayes          | 78.2%             | 81.0%         |\n",
    "| Decision Tree        | 73.4%             | 73.0%         |\n",
    "| MaxEnt               | 79.6%             | 82.2%         |\n",
    "| **Ensemble**         | 79.6%             | 81.4%         |\n",
    "\n",
    "- **MaxEnt performed best** on both dev-test and test sets.\n",
    "- **Ensemble** voting slightly improved test performance over Naive Bayes alone.\n",
    "- **Naive Bayes** revealed key linguistic patterns — e.g., names ending in `\"a\"` or `\"na\"` strongly predict female.\n",
    "- **Cross-validated NB accuracy** was stable at ~79.8%, showing generalization.\n",
    "\n",
    "These results show that even simple models can make accurate gender predictions from first names using linguistically meaningful features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fe65f6",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This project demonstrates the power of simple NLP and classification techniques in modeling patterns in human names. By combining hand-crafted features with well-known classifiers, we achieved over 82% accuracy in predicting gender from names.\n",
    "\n",
    "The MaxEnt classifier was the most effective overall, but the ensemble approach provided robustness. Importantly, the Naive Bayes model offered insight into which features were most influential — for example, suffixes like `\"na\"`, `\"ia\"`, and `\"us\"` being highly gender-specific.\n",
    "\n",
    "If expanded to larger or multilingual datasets, this approach could support applications in named entity recognition or identity prediction. Future work might involve deep learning or transformer models for more complex feature representations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b93900",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sps620env)",
   "language": "python",
   "name": "sps620env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
